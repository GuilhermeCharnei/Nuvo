# NUVO WOODWORK - Robots.txt
# Updated: 2025-10-24
# Compliance: Google Search Essentials

# Allow all search engines to crawl all content
User-agent: *
Allow: /

# Crawl-delay to prevent server overload (optional, adjust as needed)
# Crawl-delay: 1

# Sitemap location - helps search engines discover all pages
Sitemap: https://www.nuvodesigngroup.com/sitemap.xml

# Block specific paths if needed (examples below, adjust based on your needs)
# Disallow: /api/
# Disallow: /admin/
# Disallow: /_next/static/
# Disallow: /_next/image

# Allow Googlebot to crawl everything
User-agent: Googlebot
Allow: /

# Allow Googlebot Image to crawl images
User-agent: Googlebot-Image
Allow: /

# Block bad bots (optional - add known malicious bots)
User-agent: AhrefsBot
Crawl-delay: 10

User-agent: SemrushBot
Crawl-delay: 10

# Host (optional - specify preferred domain)
# Host: https://www.nuvodesigngroup.com
